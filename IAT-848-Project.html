<!DOCTYPE hmtl>
<html>
	<head>
		<meta charset="utf-8">
		<script src="https://use.fontawesome.com/d1341f9b7a.js"></script>
		<link rel="stylesheet" href="style.css">
		<title> IAT 848 project</title>
	</head>
	<body>
		<div class="topnav">
			<a class="active" href="index.html">Home</a>
			<a href="Publications.html">Publications</a>
			<a href="IAT-848-Project.html">IAT 848 course project</a>
		</div>
		<div class="box1">
			<h2> Mahdi Davoodikakhki </h2>
			<h2> Professor Steve DiPaola </h2>
			<h1>Introduction</h1>
			<p>&nbsp;&nbsp;This project is a 3D scene generation. It aims to create 3D scenes and environments in Virtual Reality platforms. 
			In this project, we tend to get the user voice input and use a speech recognition system to convert the user speech to text.</p>
			<p>This project can be completed in four steps. First, we can detect some keywords linked to certain models and instantiate the requested models where the user asks for them. Second, We should try 
			to get the whole sentences from users and understand and build the semantic graphs coming from the users. </p>
			<p>Third, adding a dialogue system between the users and the scene generator. With this dialogue, users would be able to ask for some changes, such as changing the scale, rotation, color, 
			and position of objects. Fourth, with having a large 3D dataset model, users can ask for some different type of the instantiated models.</p>
			<h1>Team members and roles</h1>
			<p>&nbsp;&nbsp;The team for doing this project has just one student, named Mahdi Davoodikakhki, and he gets guidelines from Professor DiPaola, who is the course instructor and his supervisor.
			Therefore, Mahdi is the responsible person for implementing the codes, design, writing reports, and other sections.</p>
			<h1> Implementing the Project</h1>
			<p> &nbsp;&nbsp; We have two suitable software for implementing this project. The first one is the Unity game engine, which has a proper documentation and also a big asset store that can help us
			with finding the 3D models for implementing the project. The second solution is using Tivoli Cloud VR software. 
			It seems to be an easier solution overall but for now, its documentation is not very clear as it is a rather new platform and it does not have a dataset of 3D models, 
			but it can easily gather people in an interactive environment, which is a quite worthy advantage for using that.</p>
			<p> We plan to try implementing things in Tivoli Cloud VR to test its abilities and take advantage of its interactive environment, but we will use Unity game engine as a backup software to finish the project in case
			things do not go as planned for this project on Tivoli Cloud VR.</p>
			<h1>Sketches and ideas</h1>
			<p> &nbsp;&nbsp; Here, we show a few sketches from the possible outcome of each step. Please note that the first step is done partially and the next steps sketches are created manually.</p>
			<video width="960" height="540" controls>
			  <source src="Proposal1.mp4" type="video/mp4">
			</video>
			<div class="vcaption">
				<p>The current output of the first step.</p>
			</div>
			<img width="960" src="sketch1.png"></img>
			<div class="vcaption">
				<p>First step output after asking to instantiate car, house, helicopter, and police car by pointing with handset.</p>
			</div>
			<img width="960" src="sketch2.png"></img>
			<div class="vcaption">
				<p>Second step scene similar to the first step scene. Showing the output after saying "put two cars left to a helicopter and next to a house".</p>
			</div>
			<img width="960" src="sketch3.png"></img>
			<div class="vcaption">
				<p>Third step output after saying "rotate the car 90 degrees."</p>
			</div>
			<img width="960" src="sketch4.1.png"></img>
			<div class="vcaption">
				<p>Fourth step output after saying "replace the car with a small cartoon car".</p>
			</div>
			</div class="references">
			<h1> References </h1>
			<p> A. Chang, M. Savva, and C. Manning, “Interactive Learning of Spatial Knowledge for Text to 3D Scene Generation,” in <i>Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces</i>, Baltimore, Maryland, USA, 2014, pp. 14–21.</p>
			<p> Z. Deng, J. Chen, Y. Fu, and G. Mori, “Probabilistic Neural Programmed Networks for Scene Generation,” p. 11. </div>
			</div>
			
		</div>
		
	</body>

</html>